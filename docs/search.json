[
  {
    "objectID": "gen_art/coastlines/index.html",
    "href": "gen_art/coastlines/index.html",
    "title": "Coastlines",
    "section": "",
    "text": "I created this system for the Genuary 2024 prompt “In the style of Vera Molnár” - it is inspired by her work La Ciotat. Since La Ciotat is also a French coastal town, as homage to Molnár’s work, I’ve named my pieces after some of the coastal locations that I’ve visited in the UK. The Lindisfarne pieces are the most similar to La Ciotat. The name of the system as a whole - Coastlines - also references the thin, vertical lines that are the building blocks of each piece as well as the frequent naturalistic imagery (e.g., hills or beaches).\nLicense: CC BY-NC-ND 4.0\nSet 1: Lindisfarne\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet 2: Holyrood Park\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet 3: Pentland Hills\n\n\n\n\n\n\n\n\n\n\n\n\nSet 4: Whitley Bay\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet 5: Tynemouth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet 6: Llanddwyn\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet 7: North Shields"
  },
  {
    "objectID": "gen_art/apertures/index.html",
    "href": "gen_art/apertures/index.html",
    "title": "Apertures",
    "section": "",
    "text": "This system is based on the concepts from session 2 of the Art from Code generative art tutorial.\nLicense: CC BY-SA 4.0\nSet 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet 2\n\n\n\n\n\n\n\n\n\n\n\n\nSet 3"
  },
  {
    "objectID": "gen_art/drifts/index.html",
    "href": "gen_art/drifts/index.html",
    "title": "Drifts",
    "section": "",
    "text": "This system explores the concepts from session 2 of the Art from Code generative art tutorial. It uses pattern and noise generators in the ambient package. My implementation combines Worley noise and waves, with settings that control the frequencies, noise seeds, where waves begin, and how much the waves contribute to the final pattern.\nLicense: CC BY-SA 4.0"
  },
  {
    "objectID": "data_science/seizure-states/index.html#overview",
    "href": "data_science/seizure-states/index.html#overview",
    "title": "Epilepsy research: Modulations in seizure states",
    "section": "Overview",
    "text": "Overview\nIn another post, I described my work characterising seizures as pathways and investigating how these pathways change over time. One disadvantage of this approach is that it’s tricky to quantify what parts of pathways change from seizure to seizure. For example, we might want to ask whether seizures that occur at a certain time of day all share a certain feature. I therefore developed a complementary approach: describing seizures as state progressions, where each state in a seizure captures a particular pattern of brain activity. I could then quantify which states appeared in each seizure (state occurrence) and how long each state lasted (state duration).\n\n\n\n\n\n\n\nSchroeder et al. 2023, Brain Communications\n\n\nI applied this approach to a unique dataset of chronic (spanning multiple months) recordings of brain activity in ten people with epilepsy, allowing me to investigate how seizure states change over days, weeks, and months. For example, the occurrence of many states changed over the course of a subject’s recording:\n\n\n\n\n\n\n\nSchroeder et al. 2023, Brain Communications\n\n\nI was particularly interested in cyclical changes in seizure states, as seizure risk is known to vary over daily and multi-day cycles. I therefore extracted cycles in a biomarker of pathological brain activity and compared seizure states to these cycles. This analysis revealed that seizure states often vary cyclically.\n\n\n\n\n\n\n\nSchroeder et al. 2023, Brain Communications\n\n\nUnderstanding how seizures change over different timescales could lead to new treatments that adapt over time to control different types of seizures."
  },
  {
    "objectID": "data_science/seizure-states/index.html#my-contributions",
    "href": "data_science/seizure-states/index.html#my-contributions",
    "title": "Epilepsy research: Modulations in seizure states",
    "section": "My contributions",
    "text": "My contributions\nThis project was part of my PhD thesis; I was responsible for shaping the project’s direction, undertaking the analyses, and communicating the findings. The brain recording data was obtained and organised by collaborators from another research institution, who also provided feedback throughout the project."
  },
  {
    "objectID": "data_science/seizure-states/index.html#data-science-approaches",
    "href": "data_science/seizure-states/index.html#data-science-approaches",
    "title": "Epilepsy research: Modulations in seizure states",
    "section": "Data science approaches",
    "text": "Data science approaches\n\nSignal processing: I used signal processing techniques such as filtering to preprocess brain signals.\nNetwork analysis: I described seizure dynamics as the time-varying network interactions between pairs of brain regions.\nClustering and dimensionality reduction: I used non-negative matrix factorisation as a soft-clustering method to extract recurring seizure states from time-varying seizure network interactions.\nTime series decomposition: I extracted cycles in brain activity using empirical mode decomposition, which decomposes a time series into oscillations at different frequencies. Unlike many other frequency decomposition approaches, empirical mode decomposition does not require the extracted cycles to be regular; it can capture prominent cycles even if the cycle period varies (e.g., if the cycle peaks every five to seven days instead of exactly every six days).\nCircular and non-parametric statistics: To characterise cycles in seizure states, I used a range of statistics, including Wilcoxon rank sum tests, phase locking values, and circular-linear correlation."
  },
  {
    "objectID": "data_science/epilepsy-abnormalities/index.html",
    "href": "data_science/epilepsy-abnormalities/index.html",
    "title": "Epilepsy research: Do brain abnormalities change over time?",
    "section": "",
    "text": "The full details for this project are available in our open access paper, Temporal stability of intracranial electroencephalographic abnormality maps for localizing epileptogenic tissue. My Python code for generating the main figures is available on my GitHub."
  },
  {
    "objectID": "data_science/epilepsy-abnormalities/index.html#overview",
    "href": "data_science/epilepsy-abnormalities/index.html#overview",
    "title": "Epilepsy research: Do brain abnormalities change over time?",
    "section": "Overview",
    "text": "Overview\nWhen seizures are not controlled by medication, one of the few remaining treatment options is brain surgery to remove the part of the brain that causes seizures. However, identifying those regions can be difficult, and people with epilepsy often continue having seizures after surgery. The main focus of my postdoc research is developing computational measures that help pinpoint pathological brain regions so that they can successfully be removed.\nThis study investigated the stability of one of our measures of brain “abnormalities” that we use to identify pathological brain regions. Our measure is computed from intracranial EEG, which is recorded from electrodes that are temporarily implanted directly on or in the brain. These recordings are usually multiple days and capture a variety of brain activity, including periods of sleep, wake, and seizures. To use our abnormality measure clinically, we first need to know whether the measure is robust. How much is it influenced by the type of brain activity? How much data is needed to reliably compute our measure?\nTo determine the impact of removing brain abnormalities, we additionally computed a summary metric, DRS, that captures differences in abnormality levels between the resected (i.e., hypothesised to be pathological) and spared (thought to be healthy) brain regions. We expected DRS to differ depending on whether the subject was seizure free after surgery – indicating that the hypothesised pathological regions indeed caused seizures – or not seizure free.\nWe found that although there is some variability in abnormalities at the level of different brain regions, the relationship between resected and spared brain regions (as captured by the metric DRS) remained relatively consistent over time in each subject. Additionally, we could use DRS to distinguish subjects that were seizure free versus not seizure free after surgery.\nWe used a variety of plots to visualise the data at the level of individual subjects as well as the entire cohort - I’ve included a couple examples here. This figure shows that brain abnormalities and the summary DRS metric were similar in time periods close to seizures (“peri-ictal”) and far away from seizures (“interictal”). Subjects were divided by whether they had good (ILAE 1, blue) or poor (ILAE 2-5, red) treatment outcomes.\n\n\n\n\n\n\n\nWang et al. 2023, Brain Communications\n\n\nThe figure below summarises results across subjects. We show the distribution of our summary measure in each subject and then used a machine learning classification metric to evaluate whether our measure distinguished subjects by their surgical outcomes.\n\n\n\n\n\n\n\nWang et al. 2023, Brain Communications"
  },
  {
    "objectID": "data_science/epilepsy-abnormalities/index.html#my-contributions",
    "href": "data_science/epilepsy-abnormalities/index.html#my-contributions",
    "title": "Epilepsy research: Do brain abnormalities change over time?",
    "section": "My contributions",
    "text": "My contributions\nThis project was a collaborative effort between five members of the lab as well as our clinical collaborators. Throughout the project, we met regularly to discuss preliminary results and brainstorm next steps. I was heavily involved in the analysis and writing. I worked with two other lab members to process and analyse the brain recording data, then drafted the manuscript’s methods, results, and supplementary material. I also generated most of the figures and final documented code, with feedback from the group."
  },
  {
    "objectID": "data_science/epilepsy-abnormalities/index.html#data-science-approaches",
    "href": "data_science/epilepsy-abnormalities/index.html#data-science-approaches",
    "title": "Epilepsy research: Do brain abnormalities change over time?",
    "section": "Data science approaches",
    "text": "Data science approaches\n\nData wrangling: Our lab has collaboratively created a large database of iEEG data along with patient, recording, and brain region metadata. A subset of this data was used and further organised for this project.\nSignal processing and time series frequency decomposition: We analysed brain activity in the frequency domain by computing power spectral densities and band power.\nNormative mapping: To determine if brain regions were abnormal, we compared brain activity in each patient to a normative map of our measure. This map describes normal brain dynamics in each brain region and was created using non-pathological brain regions from over 200 subjects from a separate iEEG study. Importantly, the normative map accounts for the well-known spatial variability in brain activity, allowing us to compare brain regions with different expected profiles of activity.\nMachine learning classification metrics: We defined our summary measure, DRS, as the area under the curve (AUC) for distinguishing resected and spared brain regions using abnormalities. We also used AUC to quantify whether DRS distinguishes patients who had good versus poor treatment outcomes.\nNon-parametric statistics: We used Wilcoxon rank sum tests to test whether our metric DRS significantly different between patients with good and patients with poor treatment outcomes.\nDimensionality reduction and time series decomposition: As part of the exploratory phase of this project, we also used approaches such as non-negative matrix factorisation and empirical mode decomposition to investigate possible spatiotemporal patterns in patient abnormalities."
  },
  {
    "objectID": "data_science/seizure-pathways/index.html",
    "href": "data_science/seizure-pathways/index.html",
    "title": "Epilepsy research: Variability in seizure pathways",
    "section": "",
    "text": "This work is published in Seizure pathways change on circadian and slower timescales in individual patients with focal epilepsy and Multiple mechanisms shape the relationship between pathway and duration of focal seizures."
  },
  {
    "objectID": "data_science/seizure-pathways/index.html#overview",
    "href": "data_science/seizure-pathways/index.html#overview",
    "title": "Epilepsy research: Variability in seizure pathways",
    "section": "Overview",
    "text": "Overview\nAlthough it is well-established that brain dynamics vary over time, we are just beginning to understand how that variability impacts neurological disorders. In people with epilepsy, fluctuations in brain dynamics impact not only when seizures occur but also features such as symptoms and seizure spread. My PhD research focused on visualising and quantifying this variability, with ultimate goal of inspiring treatments that adapt to changing brain dynamics.\nQuantitatively comparing seizures is challenging because seizures are such complex events. They have both spatial and temporal features: they change the activity of multiple brain regions, and that activity evolves from seizure start to finish. Seizures therefore need to be described using multivariate time series that capture spatiotemporal changes in brain dynamics. I described these time series as pathways through the space of possible brain dynamics.\nI visualised seizure pathways in two dimensions using a dimensionality reduction technique that tries to maintain high dimensional distances in a lower dimensional space; it essentially squishes the data into two dimensions so that it’s easier to visually compare different observations. This representation isn’t perfect, but it’s a good way to start investigating the structure and relationships in complex data.\nHere’s an example of this approach using one subject’s seizures. Each point represents the brain’s activity during a short part of a seizure. Points that are closer together represent similar patterns of brain activity. By connecting points in the same seizure, we see how brain activity changes during the seizure; this line is the seizure’s pathway.\n\n\n\n\n\nHere are more seizures from the same subject - you can see the seizure variability from both the brain recordings (A) and seizure pathways (C). I also quantified the “distance” or dissimilarity between each pair of pathways (D) to have an objective comparison of seizure pathways for downstream analysis.\n\n\n\n\n\n\n\nSchroeder et al. 2020, PNAS\n\n\nOne of my first observations was that different types of seizure pathways do not occur randomly - instead, more similar seizures tended to occur close together in time. For example, in (A) below, the purple seizure pathways migrated through network space as time passed, with similar pathways (e.g., seizures 6-8) occurring back-to-back. The rest of the figure quantifies the relationship between seizure pathways and their “temporal distance”: the amount of time between each pair of seizures.\n\n\n\n\n\n\n\nSchroeder et al. 2020, PNAS\n\n\nImportantly, quantifying seizure variability paves the way for additional studies by providing an objective measure of seizure (dis)similarity. For example, in my next study I asked if seizures with similar pathways also last a similar amount of time. I found that these different features weren’t necessarily linked (as shown by the examples below), which suggests that seizure pathways and durations can be altered by different mechanisms.\n\n\n\n\n\n\n\nSchroeder et al. 2022, Brain Communications"
  },
  {
    "objectID": "data_science/seizure-pathways/index.html#my-contributions",
    "href": "data_science/seizure-pathways/index.html#my-contributions",
    "title": "Epilepsy research: Variability in seizure pathways",
    "section": "My contributions",
    "text": "My contributions\nMy PhD research involved independent projects under the guidance of my supervisor. I undertook the analyses, communicated the results in papers and presentations, and drove the research directions. Throughout the projects, I incorporated feedback from the lab and our clinical collaborators."
  },
  {
    "objectID": "data_science/seizure-pathways/index.html#data-science-approaches",
    "href": "data_science/seizure-pathways/index.html#data-science-approaches",
    "title": "Epilepsy research: Variability in seizure pathways",
    "section": "Data science approaches",
    "text": "Data science approaches\n\nData wrangling: For this project, I extracted and organised seizure brain recordings, seizure metadata, and subject metadata.\nSignal processing: I used signal processing techniques such as filtering to preprocess brain signals.\nNetwork analysis: I described seizure dynamics as the time-varying functional connectivity between pairs of brain regions. Functional connectivity is a type of network that describes the similarity of pairs of time series (e.g., brain activity). I used coherence to quantify the similarity of pairs of brain signals in the frequency domain. I described each seizure’s time-varying network evolution as a pathway through the high dimensional network space.\nDimensionality reduction: I used non-negative matrix factorisation to reduce the dimensionality of the seizure networks and multidimensional scaling to visualise changes in seizure dynamics in a two dimensional space.\nTime series analysis: Seizure pathways are multivariate time series. To compare these time series, I used dynamic time warping and distance metrics. Dynamic time warping stretches pairs of time series to align similar dynamics, making it a useful approach for comparing time series that evolve at different rates. For example, two seizures may spread in a similar pattern, but at different rates. Dynamic time warping allows us to recognise their similar pathway, even though they progress through the pathway at different speeds.\nNon-parametric statistics: I used permutation tests to test for associations between seizure pathways and other seizure features.\nSimulations and modelling: I compared the observed changes in seizure pathways to a simple model of how seizures could change over different timescales.\nClustering: I used clustering approaches such as hierarchical clustering and k-means clustering to cluster seizures based on their features, as well as cluster evaluation metrics to determine the optimal number of clusters."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Gabrielle M. Schroeder\n\n\nData Science - Data Visualisation - Software Engineering\n\n\n  \n    \n  \n  \n\nHi, I’m Gabrielle. I am a research software engineer and data visualisation enthusiast from Newcastle upon Tyne, UK.\nRead more about me or see examples of my data science, data visualisation, and generative art projects."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Gabrielle M. Schroeder",
    "section": "",
    "text": "I am a research software engineer from Newcastle upon Tyne with a passion for uncovering and communicating insights from data.\nMy interest in data analysis was sparked by working with genetics data as an experimental biologist. In 2014, a Fulbright Postgraduate Award gave me the opportunity to transition to computational neuroscience, which included learning data science and programming. I now use those skills to develop data science and software solutions for a variety of research projects at Newcastle University.\nI particularly enjoy data visualisation, especially when it involves finding creative ways to tell stories or developing custom ways to explore complex data.\n\nEducation\nPhD in Computer Science | June 2022\nNewcastle University, Newcastle upon Tyne, UK\nMSc in Neuroinformatics | Dec. 2015\nNewcastle University, Newcastle Upon Tyne, UK\nBSc in Biological Sciences | May 2014\nRaleigh, North Carolina, US"
  },
  {
    "objectID": "data_vis.html",
    "href": "data_vis.html",
    "title": "Data visualisation",
    "section": "",
    "text": "I use personal projects to learn new tools, practice design concepts, and experiment with different visualisation techniques. Many of my projects are part of community initiatives such as Viz for Social Good (VFSG) and Tidy Tuesday.\nFor more examples, see my data science projects."
  },
  {
    "objectID": "data_vis.html#projects",
    "href": "data_vis.html#projects",
    "title": "Data visualisation",
    "section": "Projects",
    "text": "Projects"
  },
  {
    "objectID": "data_vis/vfsg-gdri/index.html",
    "href": "data_vis/vfsg-gdri/index.html",
    "title": "Viz for Social Good: Global Deaf Research Institute",
    "section": "",
    "text": "I made these visualisations for the May 2024 Viz for Social Good project for the Global Deaf Research Institute (GDRI). GDRI asked for assistance with visualising data from an extensive pilot survey administered to over 200 deaf Nigerians."
  },
  {
    "objectID": "data_vis/vfsg-gdri/index.html#visualisations",
    "href": "data_vis/vfsg-gdri/index.html#visualisations",
    "title": "Viz for Social Good: Global Deaf Research Institute",
    "section": "Visualisations",
    "text": "Visualisations"
  },
  {
    "objectID": "data_vis/vfsg-gdri/index.html#data-story",
    "href": "data_vis/vfsg-gdri/index.html#data-story",
    "title": "Viz for Social Good: Global Deaf Research Institute",
    "section": "Data story",
    "text": "Data story\nGDRI’s survey contained over 100 questions with variable response rates. I chose to focus on some of the questions about sign language use and fluency. I was initially curious about whether sign language fluency impacted factors like quality of life or ease of communication (e.g., with healthcare professionals). However, after an initial data exploration I found that most of the respondents were fluent in sign language, and I did not think there was sufficient data on non-sign language users to answer these questions.\nInstead, I decided to focus on some other interesting observations from my analysis of the sign language variables: 1) the large proportion of sign language users (first visualisation), and 2) the gap between hearing loss and learning sign language (second and third visualisations). I also thought that these visualisations would be informative for refining future survey questions (see “Data recommendations”)."
  },
  {
    "objectID": "data_vis/vfsg-gdri/index.html#design-decisions",
    "href": "data_vis/vfsg-gdri/index.html#design-decisions",
    "title": "Viz for Social Good: Global Deaf Research Institute",
    "section": "Design decisions",
    "text": "Design decisions\nGDRI expressed a need for visualisations for multiple scenarios (e.g., communicating with stakeholders, presentations, funding bids). I therefore decided to make a series of smaller visualisations, rather than one large visualisation, to give GDRI more flexibility with how they use the visualisations. The layouts also allow my title and caption to be cropped out if GDRI would like to provide different context. Likewise, I stuck with a white background to make it easier to embed the visualisations in reports, presentations, and any printed materials.\nI used GDRI branding from their logo and website. I used their main colours (sky blue and dark greys) for most of the visual elements and selected a constrasting accent colour (dark mustard yellow) based on some of the photos on their website. The titles use their website font, Questrial. I paired this font with Lexend, which (to my beginner typographer eyes) shares many similar features with Questrial. Lexend has more open apertures than Questrial, however, making it easier to read at small font sizes, and it’s also generally designed for accessibility. Lexend also has more available font weights than Questrial, which is useful for emphasising subsets of text in annotations."
  },
  {
    "objectID": "data_vis/vfsg-gdri/index.html#data-decisions",
    "href": "data_vis/vfsg-gdri/index.html#data-decisions",
    "title": "Viz for Social Good: Global Deaf Research Institute",
    "section": "Data decisions",
    "text": "Data decisions\nFor my first visualisation on the number of sign language users, I combined information from the “Languages you use comfortably” and “How fluent are you in sign language?” variables due to limitations in the first variable - namely, many people who were fluent in sign language did not list a sign language in their languages (see “Data recommendations” below).\nI considered someone fluent in sign language if they listed sign language in their languages or if they had at least a “neither good nor bad” level of sign language fluency. I chose this fluency cutoff for two reasons: 1) it suggested a decent level of sign language knowledge, and 2) 8 people who listed this fluency level also listed sign language in “Languages you use comfortably”, suggesting it does provide a sufficient fluency level for their needs. Meanwhile, no one with lower fluency levels listed sign language in their languages.\nI changed all the text in the languages lists to lowercase to make text searching easier, then identified specific sign languages by looking for certain phrases (determined by looking through the possible responses):\n\nNSL: “nsl”, “n.s.l”, “nigeria sign language”, and “nigerian sign language”\nASL: “asl”, “a.s.l”, “america sign language”, “english language (sign language”, “english language of sign language”, “english sign language for the deaf”, or “sign language-english”\n\nI did not include “english sign language” alone as an ASL search string because in some cases, multiple languages were listed without punctuation (e.g., “english hausa fulani sign language”). As such, it wasn’t possible to determine if “english sign language” meant “ASL” or two separate languages (i.e., English and a sign language). This conservative approach potentially missed up to seven ASL users who used this phrasing.\nOtherwise, respondents who 1) listed an unspecified/indetermine sign language or 2) expressed fluency in sign language, but didn’t list a sign language in their languages, were marked as knowing an unspecified sign language."
  },
  {
    "objectID": "data_vis/vfsg-gdri/index.html#data-recommendations",
    "href": "data_vis/vfsg-gdri/index.html#data-recommendations",
    "title": "Viz for Social Good: Global Deaf Research Institute",
    "section": "Data recommendations",
    "text": "Data recommendations\nSince this data was collected as part of a pilot survey, GDRI also asked VFSG volunteers to share any recommendations for future data collection. After working with this data, I have a few recommendations:\n\nLanguage options\nGDRI’s survey asked an open-ended question, “Languages you use comfortably.” Interestingly, 94 (!) respondents who expressed high levels of sign language fluency (“good” or “very good”) did not list a sign language in their languages. Respondents may have interpretted this question as “Spoken/written languages you use comfortably”, used terms such as “English” to refer to both spoken and signed languages, or interpretted “comfortable” in a way besides fluency (e.g., they may be uncomfortable using sign language due to discrimination). Additionally, many sign language users did not specify the sign language. Therefore, to get a more complete list of languages that respondents can use, I would suggest providing a set of checkboxes for the region’s common spoken and signed languages in the survey. This format would also make the responses consistent and therefore easier to analyse.\n\n\nClear indication of not knowing sign language\nThe survey had no clear indication of whether a respondent did not know sign language. Because many people fluent in sign language did not list a sign language in their languages, the absence of a sign language in this list was not evidence for not knowing sign language. The sign language fluency question provides a better indication, but respondents who don’t know sign language could potential skip this question if they think it only pertains to sign language users. Providing the discrete language options, as suggested above, would provide stronger evidence for not knowing sign language, and a question such as “Do you know any sign language?” may also be a useful addition.\n\n\nWant to learn sign language\nGDRI also asked respondents whether they wanted to learn sign language. Although “I already know sign language” was a possible option, many people with high levels of sign language fluency answered “yes” or “no”, which is difficult to interpret (Are they expressing that they want to learn additional sign languages? Are they communicating that they wanted to learn sign language at an earlier time?). This question may need to be re-phrased or restricted to a subset of respondents (i.e., those who respond “no” to a direct question on whether they know sign language).\n\n\nHearing loss vs. “significant” hearing loss\nI observed a gap between when people began experiencing loss and when they learned sign language. One possible explanation is that the respondents could have had gradual hearing loss that did not initially require them to learn sign language for communication. I suspect this explanation is unlikely since many respondents began losing hearing at young ages, but a more definitive answer could be provided by additional data on respondents’ hearing loss. Namely, if this trend is interesting to GDRI’s researchers, it would be useful to know at what age the respondents had “significant” hearing loss according to some measure (e.g., no longer able to understand spoken language).\n\n\nDemographics\nDuring the project kick-off, GDRI emphasised that there are different deaf populations with different experiences and needs. For example, some people are born deaf and learn sign language at an early age, while others experience gradual hearing loss as they age and are not culturally deaf. These visualisations revealled that most of the survey respondents were sign language users who experienced hearing loss in infancy, childhood, or adolescence. As such, the conclusions from this survey will be specific to this demographic. In future surveys, GDRI could focus on this demographic or experiment with different recruitment methods to survey individuals with different characteristics."
  },
  {
    "objectID": "data_vis/vfsg-gdri/index.html#code",
    "href": "data_vis/vfsg-gdri/index.html#code",
    "title": "Viz for Social Good: Global Deaf Research Institute",
    "section": "Code",
    "text": "Code\nAll visualisations were made using the R programming language. Portions of the code can be reused for future GDRI research - however, it will need to be adapted to new data sets. For example, the data wrangling steps here address the needs of these particular survey responses; another survey, with different responses, may require different cleaning steps. Additional, some of the visualisations have “hard coded” elements (e.g., the positions of some of the annotations) that would need to be manually changed for other data sets. Additionally, other surveys will likely have different results that should be highlighted using different visualisation approaches or annotations!\nR for Data Science and the associated communities are great resources for learning how to use R for data analysis. The book covers many of the approaches I used here.\nThe code is available on GitHub. Code dependencies:\n\nGDRI data (add to the data folder)\nFont files for Questrial and Lexend. Functions in lib/lib_theme.R that use these files have an optional argument for specifying the path to your local directory that contains font files.\n\n\n\n\nLicense: CC BY-NC 4.0"
  },
  {
    "objectID": "data_vis/vfsg-dwf/index.html",
    "href": "data_vis/vfsg-dwf/index.html",
    "title": "Viz for Social Good: DWF ReconciliACTIONs",
    "section": "",
    "text": "This work was a volunteer project for Viz for Social Good (VFSG) in partnership with the Gord Downie & Chanie Wenjack Fund (DWF). The DWF aims to build cultural understanding and create a path towards reconciliation between Indigenous and non-Indigenous peoples in Canada. My visualisation was one of the top five designs selected by the DWF.\nCode for the data organisation, exploration, and visualisation is available on my GitHub."
  },
  {
    "objectID": "data_vis/vfsg-dwf/index.html#design-process",
    "href": "data_vis/vfsg-dwf/index.html#design-process",
    "title": "Viz for Social Good: DWF ReconciliACTIONs",
    "section": "Design process",
    "text": "Design process\nThis project was an opportunity to stretch my design skills and practice layout, typography, and colour design concepts. It was also my first time working with branding guidelines outside of academic journal figure requirements.\n\nTools\nR, Adobe Illustrator, and Adobe InDesign.\n\n\nStorytelling\nThe DWF asked for visualisations that allowed them to explore and communicate their impact, as measured by reconciliACTIONs: meaningful actions that progress reconciliation between Indigenous and non-Indigenous peoples in Canada. I decided to make a report in a style similar to their yearly reports that would summarise their progress and be easy to share with stakeholders.\n\n\n\n\n\n\n\nThe report first lays out definitions for steps and stages (part of the DWF’s model for measuring the impact of reconciliACTIONs), while visualising progress within each of these categories. These first visualisations and descriptions give the reader a big picture overview of the DWF’s progress as well as a foundation for understanding the DWF’s model of reconciliACTIONs.\n\n\n\n\n\n\n\n\n\n\n\n\nThe next pages then explore reconciliACTIONs using the combined categorisation into both steps and stages, with each stage broken down into the five possible reconciliACTION steps. One visualisation shows how the number of reconciliACTIONs in each combined category changed over time, while the other shows the contributions of different types of reconciliACTIONs, coloured by their categories.\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, I end with a call-to-action to “Do Something” to progress reconciliation by providing a template for tracking reconciliACTIONs. The latter was inspired by the DWF’s comment that they do not have reconciliACTION data at the level of individuals – i.e., they do not know which actions any one person has taken. I therefore wanted to invite people to track their own progress. I decided to distinguish between steps, but not stages, on the tracking template since it may be more difficult for non-experts to categorise their reconciliACTIONs by stages. Additionally, most people’s reconciliACTIONs will be in only one or two of the stages, at least in the near future.\n\n\n\n\n\n\n\nThe final page of the report provides short descriptions the DWF and VFSG, as well as ways for people to find out more information about these two organisations.\n\n\n\n\n\n\n\n\n\nColours and symbols\nI worked with the DWF’s brand colours, but I also expanded the colour palette using three main hues from the striking colour palette of one of their main resources, The Secret Path film. I used the cooler hues to represent earlier stages of reconciliACTIONs, allowing the warming of the colour palette to symbolise the progression of reconciliation. Meanwhile, each step within each stage is encoded by the lightness of the hue. The colour therefore darkens as the steps become more difficult, which corresponds nicely to the increased impact of the latter steps. The combined hue and lightness encoding allowed me to visualise the combined categorisation of each reconciliACTION in the report’s latter visualisations.\nI also incorporated imagery and art that is central to the DWF’s messaging and identity, including Secret Path lyrics, train tracks, and watercolour artwork.\n\n\nData decisions\nI decided to use the simpler DWF model of “stages” of reconciliACTIONs, rather than the categorisation into “future states” of Canada, which would have doubled the number of categories. Based on my initial data explorations, I felt that the simpler stages representation captured most of the variability in the types of reconciliACTIONs thus far, and I therefore sacrificed some level of detail to make the visualisations more accessible. Further, since the report is geared towards DWF supporters and stakeholders, I thought the stages description was most appropriate since it focuses on the development of individual participants in their path to reconciliation. However, I did tie the stages back to the future states description to explain how stages fit in to the DWF’s more detailed model.\nSome of the reconciliACTIONs had negative numbers due to a decrease in the net number of newsletter subscribers. As suggested by the DWF, I decided to transform these negative numbers to zero to prevent them from detracting from other reconciliACTIONs in the same category. My reasoning was that unsubscribing did not undo or negate the participant’s previous action of subscribing. Additionally, the unsubscribing participants may decide to continue their reconciliation journey using other approaches, such as following the DWF on social media. If possible, the DWF could separately track the number of new subscriptions and unsubscriptions in future quarters to have different options for tracking these reconciliACTIONs.\nI also combined newsletter subscribers and mailable newsletter subscribers into one category for the “Many Ways to #DoSomething” visualisation of different reconciliACTION types.\n\n\nBrainstorming\nI’ve always gravitated towards sketching out visualisation ideas, but – inspired by reading about graphic and visualisation designers’ processes – I decided to more systematically incorporate sketches into developing these visualisations. Throughout the project, I used sketches to test out different ideas for vis types, layouts, and encodings. I sketched out initial ideas after first listening to the DWF’s Viz for Social Good presentation, but I also made sure to look at the data early on to understand its limitations and the feasibility of my approach. For example, I saw early on that the different scales in the data would make it tricky to compare reconciliACTIONs across different categories. I returned to sketching throughout the project to refine my early ideas, overcome roadblocks, and test out new ideas."
  },
  {
    "objectID": "data_vis/vfsg-dwf/index.html#acknowledgments",
    "href": "data_vis/vfsg-dwf/index.html#acknowledgments",
    "title": "Viz for Social Good: DWF ReconciliACTIONs",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI used a slightly modified version of a generative art system designed by Danielle Navarro to make the irregular and smudged shapes in the #DoSomething tracking template. Her code is included in the art_functions.R script and is licensed under a Creative Commons Attribution 4.0 International License. The code is available from the Art from Code tutorial, session 3 and the associated GitHub page.\nDescriptions of the DWF and VFSG organisations are from their language guidelines and website, respectively."
  },
  {
    "objectID": "data_vis/macros-map/index.html#food-selection",
    "href": "data_vis/macros-map/index.html#food-selection",
    "title": "Macronutrients Map",
    "section": "Food selection",
    "text": "Food selection\nThe full USDA food database in the {NutrienTrackeR} package has an overwhelming number of foods: 7,754 . I pared this down to 1,530 foods using a combination of subsetting, heuristics, and a small amount of manual curation. I wanted to have a wide variety of foods while focusing on 1) less specific entries, 2) fresh and unprepared foods, and 3) foods with fewer ingredients (i.e., not complete meals or dishes). However, I kept some simpler processed and multi-ingredient foods, such as bread and yoghurt. I also removed some of the more unusual entries such as “raccoon.”\nMy wrangling steps included\n\nRemoving database categories that didn’t meet my criteria (e.g., “Fast Foods” and “Restaurant Foods”).\nRemoving entries with more than six words (excluding some phrases like “without salt” from the word count since they signified a simpler version of the food). This step removed very specific entries such as “Beef, chuck, shoulder clod, shoulder top and center steaks, separable lean and fat, trimmed to 0” fat, all grades, cooked, grilled” (21 words).\nRemoving alcoholic foods and beverages since they have a fourth macronutrient - alcohol - that I didn’t want to include in this visualisation. I identified these entries by estimating each food’s calories based on their carbs, fats, and protein content. I then found foods where this calculation greatly underestimated the true calorie content (since the remaining calories come from the alcohol). I removed any remaining alcohol-related entries using string matching to the food names.\nRemoving brand name foods. The USDA database capitalises most of the company names in the database, so these were easy to filter out by finding food names with multiple consecutive capital letters. I then manually filtered out some missed branded entries.\nRemoving entries that contained words that indicated cooking or processing - e.g., “cooked”, “roasted”, or “frozen”. I was careful here to keep longer versions of these strings that indicated the opposite - e.g., “uncooked”.\n\nTogether, these steps removed a lot of redundant entries, resulting in a more manageable map to explore.\nI also think this plot would work well using more tailored data, such as food from one person’s diet."
  },
  {
    "objectID": "data_vis/macros-map/index.html#layout",
    "href": "data_vis/macros-map/index.html#layout",
    "title": "Macronutrients Map",
    "section": "Layout",
    "text": "Layout\nThis visualisation uses a dimensionality technique called t-distributed Stochastic Neighbour Embedding (t-SNE), which embeds data in a small (e.g., two) number of dimensions to make it easier to visualise. The algorithm tries to optimise the new layout so that similar observations (here, foods) are placed close together. I based the similarity of the different foods off of their relative amounts of macronutrients and their calories per 100 g. Using relative macronutrient content (e.g., 20% protein) rather than the absolute macronutrient values (e.g., 10 g protein per 100 g) means that non-caloric content, such as water, is ignored for the embedding. I also normalised these features so that higher-magnitude features (such as calories) did not have a greater impact on food similarity.\nt-SNE is not deterministic - you can get different embeddings depending on where you first place each point. It also has a parameter, perplexity, that controls how much the algorithm focuses on nearby versus global similarities. To find an embedding that worked well for this visualisation, I systematically tried different starting configurations and perplexity values. I also experimented with scaling how much calories contributed to food similarity, as I wanted the layout to be primarily driven by the macronutrient content, with calories further separating foods with similar macronutrients. Ultimately, I divided the normalised calories by four to decrease their impact on the embedding.\nThe initial t-SNE embedding that I selected looked something like this:\n\n\n\n\n\nThis plot is pretty, but difficult to interact with because of the overlap between different foods, especially with the point size scaled by calories. I therefore used the R package {packcircles} to repel nearby points, resulting in a final layout without overlapping points. I also flipped the layout to work better with my text annotations - rotated or flipped embeddings are equivalent since they have the same distances between points. Here’s a non-interactive version of the final, annotated layout:\n\n\n\n\n\nWhile making this chart, I searched for any similar visualisations. I didn’t find any maps using these exact features, but there is a published static t-SNE embedding of USDA food data that uses the complete nutritional information (including micronutrient content such as vitamins). However, there are many more types of embedding approaches, so I may have missed other macronutrient representations - if you find any, I would love to see them!"
  },
  {
    "objectID": "data_vis/gardening-covid/index.html",
    "href": "data_vis/gardening-covid/index.html",
    "title": "Gardening’s growth during COVID",
    "section": "",
    "text": "These visualisations are a small personal project to practice using R and Datawrapper."
  },
  {
    "objectID": "data_vis/gardening-covid/index.html#gardenings-growth-during-the-covid-pandemic",
    "href": "data_vis/gardening-covid/index.html#gardenings-growth-during-the-covid-pandemic",
    "title": "Gardening’s growth during COVID",
    "section": "Gardening’s growth during the COVID pandemic",
    "text": "Gardening’s growth during the COVID pandemic\nWith the weather warming up in Newcastle upon Tyne, I’ve been spending more time in our new garden. As a novice gardener, I’ve also been doing more research online, Googling how and when to plant my various vegetable and flower seeds. These searches made me wonder how other gardeners use Google. Do their searches also vary over the course of the year?\nUsing Google Trends data, I began investigating garden searches in the UK, focusing on “how to garden” to capture interest in hobby gardening. I soon found that the expected seasonal changes weren’t the most interesting pattern in recent years:\n\n\n\n\n\n(Click on the chart for an interactive version.)\nCompared to the previous five years, 2020 saw more than double the number of “how to garden” searches after the first UK COVID-19 lockdown. In hindsight, the increased searches during 2020 are unsurprising, as the COVID-19 pandemic saw a dramatic increase in hobbiest gardeners. Like the pandemic, this higher interest persisted into 2021, with 2022 also seeing somewhat elevated searches. Interestingly, 2021 also bucks the usual seasonal pattern: “how to garden” searches increased a month earlier than expected, suggesting that gardeners were eager to get back outdoors after a winter of lockdowns!\nI can think of two main possibilities for the increased gardening interest:\n\nPeople looking for new at-home hobbies for themselves or their families. Many people had more free time due to furlough or working from home, and many usual hobbies and social activities were restricted by lockdowns.\nPeople who wanted access to fresh food without risking exposure to COVID-19 in shops or dealing with strange grocery delivery substitutions.\n\nTo better understand what drove the pandemic gardening Google searches, I investigated two more specific search terms: “how to grow vegetables” and “how to grow flowers.”\n\n\n\n\n\nBoth of these searches also dramatically increased during the first year of lockdowns. Although some flowers are edible or good companion plants, we can probably assume that flower searches were mostly hobby-motivated. Growing vegetables can also primarily be a hobby, but, interestingly, vegetable searches increased both sooner and more than flower searches in 2020. While home-grown crops take time to bear fruit (or veg), some searches may have been driven by initial lockdown fears or food order frustrations - especially if people suspected the pandemic would last beyond the first three week lockdown."
  },
  {
    "objectID": "data_vis/gardening-covid/index.html#bonus-stand-alone-r-visualisation",
    "href": "data_vis/gardening-covid/index.html#bonus-stand-alone-r-visualisation",
    "title": "Gardening’s growth during COVID",
    "section": "Bonus stand-alone R visualisation",
    "text": "Bonus stand-alone R visualisation\n\n\n\n\n\nHere I’ve added a third, more generic search: “how to grow food.” Food searches also increased during COVID, suggesting at least some gardening interest was driven by people who wanted to grow their own food."
  },
  {
    "objectID": "data_vis/tidy-tuesday/index.html",
    "href": "data_vis/tidy-tuesday/index.html",
    "title": "Tidy Tuesday (2023)",
    "section": "",
    "text": "These are my visualisations for Tidy Tuesday: a weekly R for Data Science data wrangling and visualisation challenge. Rough code for these visualisations is available on my GitHub.\n\nWeek 25: UFO Sightings\nI visualised when UFO sightings occur during the day and year. In the US, sightings tend to occur during the last few hours (during summer) or several hours (during winter) of the day, and sightings are especially common on Jan. 1 and July 4. The seasonal time-of-day variability in sightings may be because sightings tend to occur during dusk or the first part of the night.\n\n\n\n\n\n\n\n\n\n\nFewer UFO sightings were reported in the United Kingdom, but there are still some interesting trends:\n\n\n\n\n\n\n\nWeek 22: Verified Oldest People\nI visualised the years the oldest men and women lived and highlighted the people who set record ages."
  },
  {
    "objectID": "data_vis/vfsg-impact/index.html",
    "href": "data_vis/vfsg-impact/index.html",
    "title": "Viz for Social Good: VFSG Impact, 2017-2023",
    "section": "",
    "text": "This Viz For Social Good (VFSG) project focused on VFSG’s own data on volunteer submissions and non-profit partners. I chose to make data art of each past VFSG project, with the goal of creating engaging visualisations that also celebrate VFSG’s community and growth.\nI used the projects brief’s description of VFSG’s visualisations as “beacon[s] of change” as inspiration. For each project, the volunteers’ visualisations are represented by rays of light that illuminate the mission and impact of the project’s non-profit partner (represented by the layered geometric shape).\nHere are the pieces for the two projects I participated in last year (which are also two of my favourite outputs):"
  },
  {
    "objectID": "data_vis/vfsg-impact/index.html#how-to-read",
    "href": "data_vis/vfsg-impact/index.html#how-to-read",
    "title": "Viz for Social Good: VFSG Impact, 2017-2023",
    "section": "How to Read",
    "text": "How to Read\nData art is not designed to be the most effective at encoding or analysing data - for example, it’s difficult to directly compare the number of visualisations submitted for different projects using these illustrations. However, I wanted the data encoding to be apparent so each piece provides a general impression of the project’s data.\nEach submitted data visualisation is represented by one ray:\n\n\n\n\n\n\n\nThe corresponding non-profit for each project is represented by a geometric shape created by layering many regular polygons with the same number of sides. The number of sides is determined by the non-profit’s follower count on social media (more followers = more sides) as a rough approximation of its reach and recognisability. Smaller non-profits often benefit the most from VFSG’s work since they usually lack the resources for an internal data analysis team.\n\n\n\n\n\n\n\n\n\n\n\n\nTap Elderly Women’s Wisdom for Youth, with a little over a 100 followers on X (Twitter), vs. UNICEF, with over 9 million followers.\nThe colour of each shape is determined by the project’s primary topic. I grouped the provided topics into six broader categories:\n\nEducation (pink/orange)\nAmplifying voices (i.e., broadcasting the work and missions of other people or organisations across multiple categories) (yellow orange)\nInfrastructure, resources, and sustainability (yellow)\nEnvironment and conservation (teal/green)\nHealth (blue)\nWelfare, rights, and equality (purple)\n\nExamples of the above categories, from left to right:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(proper legend for the non-profits TBA!)"
  },
  {
    "objectID": "data_vis/vfsg-impact/index.html#highlighted-examples",
    "href": "data_vis/vfsg-impact/index.html#highlighted-examples",
    "title": "Viz for Social Good: VFSG Impact, 2017-2023",
    "section": "Highlighted examples",
    "text": "Highlighted examples\nPrevious projects using VFSG data:\n\n\n\n\n\n\n\n\n\n\n\n\nVFSG’s first and latest projects:\n\n\n\n\n\n\n\n\n\n\n\n\nThe project with the highest number of submissions:\n\n\n\n\n\n\n\nThe first project featuring presented visualisations:"
  },
  {
    "objectID": "data_vis/vfsg-impact/index.html#all-projects",
    "href": "data_vis/vfsg-impact/index.html#all-projects",
    "title": "Viz for Social Good: VFSG Impact, 2017-2023",
    "section": "All projects",
    "text": "All projects"
  },
  {
    "objectID": "data_vis/vfsg-impact/index.html#data-cleaning-and-analysis",
    "href": "data_vis/vfsg-impact/index.html#data-cleaning-and-analysis",
    "title": "Viz for Social Good: VFSG Impact, 2017-2023",
    "section": "Data cleaning and analysis",
    "text": "Data cleaning and analysis\nI used R (code in this GitHub repo) for the data analysis and visualisations. VFSG provided all of the data except for the non-profit social media follower counts.\n\nCollaborations\nSometimes, volunteers work together and submit a collaborative visualisation. I counted each unique collaboration as a separate “volunteer” when calculating volunteer submission numbers. However, a collaborative submission also counts towards the total number of submissions of the individual volunteers in the collaboration. This approach only makes a difference to the submission counts of volunteers who submitted a collaborative visualisation and then a solo visualisation for a later project.\n\n\nProject topics\nVFSG assigned 20 different topics to the 48 projects. To focus on high-level differences in project topics, I grouped these topics into six more general ones:\n\n“Environmental Impact” and “Conservation” were collapsed into Environment and conservation.\n“Homelessness,” “Financial support,” “Human Rights,” “Gender Equality,” “Crisis,” “Children and Youth,” and “Recycling” were were grouped into Welfare, rights, and equality. At first, “Recycling” might seem like a better fit for Environment and conservation. However, the “Recycling” project was Furniture Bank, whose primary focus is a welfare and equality challenge: ending furniture poverty.\nEducation and Health were already large, distinct categories, and I kept these in the simplified list. Health includes both the original “Health” and “Healthcare” topics.\nI combined “Energy/ Sustainability,” “Energy,” “Sanitation,” “Water management,” “Infrastructures,” and “Sustainable Development” into Infrastructure, resources, and sustainability.\nThe remaining original topics were “Data” (for past projects on VFSG’s impact) and “Community” (for projects with Video Volunteers and Fondation Follereau). Fondation Follereau’s project fit well in Welfare, rights, and equality. VFSG and Video Volunteers were both similar in that they help raise awareness of a range of issues by helping individuals and organisations. I therefore created a new category, Amplifying voices, to describe these projects.\n\nMany projects could belong to multiple categories, especially due to the interactions between many of these categories. Despite these limitations, these groupings provide a general impression of the types of organisations VFSG has collaborated with.\n\n\nFollower counts\nI manually collected each non-profit’s number of followers on X (Twitter) on 12 April, 2024, to provide a rough measure of the non-profit’s reach and level of recognition. The number of sides in each visualisation is a log-transformed and scaled version of the follower count. The Keith Richardson Foundation does not have an X account, so I used their Instagram follower count instead. This measure could be improved by summarising follower information from multiple social media accounts.\n\n\n\nLicense: CC BY-NC 4.0"
  },
  {
    "objectID": "data_vis/vfsg-who/index.html",
    "href": "data_vis/vfsg-who/index.html",
    "title": "Viz for Social Good: World Health Organisation",
    "section": "",
    "text": "I designed this visualisation for Viz for Social Good’s collaboration with the World Health Organisation (WHO). For this project, the WHO provided a dataset on global disabilities; their report on the data is available here. The WHO asked for impactful visualisations that raised awareness about disability. It was also key that the visualisation was accessible (e.g., by meeting accessibility standards). My visualisation was one of five (of 49) designs selected by the WHO for a panel presentation."
  },
  {
    "objectID": "data_vis/vfsg-who/index.html#anyone-can-have-a-disability",
    "href": "data_vis/vfsg-who/index.html#anyone-can-have-a-disability",
    "title": "Viz for Social Good: World Health Organisation",
    "section": "Anyone can have a disability",
    "text": "Anyone can have a disability\nThe visualisation above represents every 1 million people in the world with one small dot. About 8,000 dots are grouped together in a circle to represent the global population of almost 8 billion people. Approximately 1 in 6 of these dots (around 1,300 dots total) are highlighted to represent the 1.3 billion people living with disabilities worldwide.\nPeople with disabilities are diverse:\n\nThey can be any sex: 44% are male and 56% are female\nThey can be any age: 7% are 0 to 14 years old, 63% are 15 to 59 years old, and 30% are at least 60 years old\nAnd they live in countries with different income levels: 7% in low income, 40% in lower-middle income, 33% in upper-middle income, and 20% in high income countries\n\nThese factors all impact the health inequities experienced by people with disabilities.\nVisualisation sources:\n\nVisualisation by Gabrielle M. Schroeder\nData source: World Health Organisation (2021 global disability data)\nViz for Social Good volunteer project"
  },
  {
    "objectID": "data_vis/vfsg-who/index.html#story",
    "href": "data_vis/vfsg-who/index.html#story",
    "title": "Viz for Social Good: World Health Organisation",
    "section": "Story",
    "text": "Story\nI chose to present the key message that I took away from the WHO’s VFSG presentation: anyone can have a disability. In particular, disability is (1) common, and (2) impacts people with many different demographics. In other words, people with disabilities are a large and diverse group. I decided to keep the data analysis and statistics fairly simple to focus on this main message.\nAs such, I used the demographic information to answer the question, “What are the characteristics of people with disabilities?” (for example, what percentage of people with disabilities are female?) Importantly, my approach does not reveal the prevalence within each demographic, which could potentially lead to misinterpretations. For example, someone might assume that disability is less prevalent in high-income countries, even though high-income countries actually have the highest prevalence (see pages 23-24 of the WHO disability report). However, my visualisation can also correct erroneous assumptions. For example, although people who are 60+ years old are more likely to have a disability, the global population structure means that most people with disabilities are actually under 60 years old. Thus, these statistics can challenge stereotypes about people with disabilities.\nI also wanted to present this data in a memorable and impactful way. One of my first experiences seeing data visualisation used as a story-telling tool was the New York Time’s article on how race impacts economic mobility. Rather than just presenting bar charts or a Sankey diagram, the article uses animated points to represent the economic outcomes of individual people. Years later, I still remember that message because the data was connected to individuals. Inspired by that approach, I decided to try capturing the global scale and impact of disabilities by representing every one million people with one small point. Without animations, I don’t expect my visualisation to have the same impact as the New York Times charts, but my hope is that this visualisation will encourage people to sit with the data and mentally grasp the number of people living with disabilities. However, representing the data this way could also lead to accessibility issues if people struggle to perceive the small dots. I aimed to address these issues with other design choices (discussed below)."
  },
  {
    "objectID": "data_vis/vfsg-who/index.html#accessibility",
    "href": "data_vis/vfsg-who/index.html#accessibility",
    "title": "Viz for Social Good: World Health Organisation",
    "section": "Accessibility",
    "text": "Accessibility\n\nData encoding\nAs I described above, I decided to represent one million people with a small dot. I then coloured these dots based on the people’s characteristics - e.g., whether they have disabilities. Since these small elements could be difficult for people with visual impairments to perceive, I ensured that all of the statistics were also encoded by the shapes formed by the dots:\n\nWhile the dots represented by people with disabilities are mixed into the circle that forms the global population, I extract those dots into a second, smaller circle that represents people with disabilities. The relative areas of those two circles encode the percentage of people with disabilities: the people with disabilities circle is approximately 1/6th the area of the global population circle.\nThe demographic information forms stacked bar charts, with the length of each section encoding the corresponding percentage. This double encoding should help everyone understand the data, as it’s much easier to perceive differences in lengths than differences in dot numbers.\n\n\n\nColour\nI avoided using the most problematic colour combinations for people with colour vision deficiencies, but I didn’t want to rely on that approach, especially since there are many different types of deficiencies. Therefore, to make my visualisation accessible, I also ensured that (1) neighbouring colours were differentiated by lightness as well as hue, and (2) no data encodings relied on colour alone. For example, each bar chart has vertical lines marking the boundaries between groups.\nTo check the impact of my colour choices on accessibility, I used Adobe’s colourblind checker and the Colbis (Color Blindness Simulator).\n\n\nFont, text, and contrast\nAfter researching factors that impact font accessibility, I decided to use Atkinson Hyperlegible, a font designed by the Braille Institute for people with low vision. It’s also freely available under the Open Font License, which was one of my requirements. Atkinson Hyperlegible uses extra space and exaggerated letterforms to make it easier to distinguish similar characters. The designed asymmetries also make it easier to distinguish letters that are mirror images of each other, such as p and q (e.g., compare the q in “inequities” vs. the p in “people” in my visualisation). The font was designed to be suitable for general audiences as well, and the distinct letterforms can improve readability for many people.\nAll of my text is either dark grey or purple that meets the WCAG 2.1 AAA standards for contrast against the white background (checked using Adobe’s accessibility tools). I also checked the contrast of the purple dots against the grey dots in the “global population” circle.\nThe size of all of the text is 10+ pt when the image width is 6.5+ inches, with the most important messages in larger font sizes. The visualisation has a high resolution so that it can be viewed at a larger size if desired.\n\n\nData accessibility\nThe image has the following alt text:\nA visualisation that represents every 1 million people in the world with one dot to show that 1 in 6 people, or 1.3 billion people worldwide, have a significant disability. To show the diversity of people with disabilities, the dots are rearranged into three stacked bar charts that provide sex, age, and country income level demographics.\nOne downside of using R to make a static visualisation is that, to my knowledge, there isn’t a way to allow screen readers to navigate the different chart elements. To make sure the key messages are still accessible, I also provide a text version of the main messages and statistics below the visualisation."
  },
  {
    "objectID": "data_vis/vfsg-who/index.html#other-design-choices",
    "href": "data_vis/vfsg-who/index.html#other-design-choices",
    "title": "Viz for Social Good: World Health Organisation",
    "section": "Other design choices",
    "text": "Other design choices\n\nColour significance\nDuring this project, I learned that there are many colours used to represent different types of disability. I chose purple, which is becoming a symbol of disability as a whole.\n\n\nTool\nI made this visualisation using the R programming language, both for personal reasons (wanting to practice using the tidyverse/ggplot2 packages) and to have the large amount of control over the plot and text that R provides. The code is available on my GitHub.\n\n\n\nLicense: CC BY-NC 4.0"
  },
  {
    "objectID": "gen_art.html",
    "href": "gen_art.html",
    "title": "Generative art",
    "section": "",
    "text": "I started experimenting with generative art while learning R. These pieces were created by programs that generate data using specific rules. By modifying the settings and incorporating randomness, the programs can produce qualitatively different outputs. I enjoy discovering the variety of outputs a system can create within its constraints.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoastlines\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApertures\n\n\n\nR\n\n\nambient\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDrifts\n\n\n\nR\n\n\nambient\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data_science.html",
    "href": "data_science.html",
    "title": "Data science",
    "section": "",
    "text": "As a researcher in the Computational Neurology, Neuroscience, and Psychiatry (CNNP) Lab, I used a variety of data science techniques to uncover patterns in epileptic brain activity. More information about these projects is available in the corresponding open access papers."
  },
  {
    "objectID": "data_science.html#projects",
    "href": "data_science.html#projects",
    "title": "Data science",
    "section": "Projects",
    "text": "Projects"
  }
]