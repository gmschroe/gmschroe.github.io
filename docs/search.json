[
  {
    "objectID": "gen_art/apertures/index.html",
    "href": "gen_art/apertures/index.html",
    "title": "Apertures",
    "section": "",
    "text": "This system is based on the concepts from session 2 of the Art from Code generative art tutorial.\nSet 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet 2"
  },
  {
    "objectID": "gen_art/drifts/index.html",
    "href": "gen_art/drifts/index.html",
    "title": "Drifts",
    "section": "",
    "text": "This system explores the concepts from session 2 of the Art from Code generative art tutorial. It uses pattern and noise generators in the ambient package. My implementation combines Worley noise and waves, with settings that control the frequencies, noise seeds, where waves begin, and how much the waves contribute to the final pattern."
  },
  {
    "objectID": "data_science/seizure-states/index.html#overview",
    "href": "data_science/seizure-states/index.html#overview",
    "title": "Epilepsy research: Modulations in seizure states",
    "section": "Overview",
    "text": "Overview\nIn another post, I described my work characterising seizures as pathways and investigating how these pathways change over time. One disadvantage of this approach is that it’s tricky to quantify what parts of pathways change from seizure to seizure. For example, we might want to ask whether seizures that occur at a certain time of day all share a certain feature. I therefore developed a complementary approach: describing seizures as state progressions, where each state in a seizure captures a particular pattern of brain activity. I could then quantify which states appeared in each seizure (state occurrence) and how long each state lasted (state duration).\n\n\n\n\n\n\n\nSchroeder et al. 2023, Brain Communications\n\n\nI applied this approach to a unique dataset of chronic (spanning multiple months) recordings of brain activity in ten people with epilepsy, allowing me to investigate how seizure states change over days, weeks, and months. For example, the occurrence of many states changed over the course of a subject’s recording:\n\n\n\n\n\n\n\nSchroeder et al. 2023, Brain Communications\n\n\nI was particularly interested in cyclical changes in seizure states, as seizure risk is known to vary over daily and multi-day cycles. I therefore extracted cycles in a biomarker of pathological brain activity and compared seizure states to these cycles. This analysis revealed that seizure states often vary cyclically.\n\n\n\n\n\n\n\nSchroeder et al. 2023, Brain Communications\n\n\nUnderstanding how seizures change over different timescales could lead to new treatments that adapt over time to control different types of seizures."
  },
  {
    "objectID": "data_science/seizure-states/index.html#my-contributions",
    "href": "data_science/seizure-states/index.html#my-contributions",
    "title": "Epilepsy research: Modulations in seizure states",
    "section": "My contributions",
    "text": "My contributions\nThis project was part of my PhD thesis; I was responsible for shaping the project’s direction, undertaking the analyses, and communicating the findings. The brain recording data was obtained and organised by collaborators from another research institution, who also provided feedback throughout the project."
  },
  {
    "objectID": "data_science/seizure-states/index.html#data-science-approaches",
    "href": "data_science/seizure-states/index.html#data-science-approaches",
    "title": "Epilepsy research: Modulations in seizure states",
    "section": "Data science approaches",
    "text": "Data science approaches\n\nSignal processing: I used signal processing techniques such as filtering to preprocess brain signals.\nNetwork analysis: I described seizure dynamics as the time-varying network interactions between pairs of brain regions.\nClustering and dimensionality reduction: I used non-negative matrix factorisation as a soft-clustering method to extract recurring seizure states from time-varying seizure network interactions.\nTime series decomposition: I extracted cycles in brain activity using empirical mode decomposition, which decomposes a time series into oscillations at different frequencies. Unlike many other frequency decomposition approaches, empirical mode decomposition does not require the extracted cycles to be regular; it can capture prominent cycles even if the cycle period varies (e.g., if the cycle peaks every five to seven days instead of exactly every six days).\nCircular and non-parametric statistics: To characterise cycles in seizure states, I used a range of statistics, including Wilcoxon rank sum tests, phase locking values, and circular-linear correlation."
  },
  {
    "objectID": "data_science/epilepsy-abnormalities/index.html",
    "href": "data_science/epilepsy-abnormalities/index.html",
    "title": "Epilepsy research: Do brain abnormalities change over time?",
    "section": "",
    "text": "The full details for this project are available in our open access paper, Temporal stability of intracranial electroencephalographic abnormality maps for localizing epileptogenic tissue. My Python code for generating the main figures is available on my GitHub."
  },
  {
    "objectID": "data_science/epilepsy-abnormalities/index.html#overview",
    "href": "data_science/epilepsy-abnormalities/index.html#overview",
    "title": "Epilepsy research: Do brain abnormalities change over time?",
    "section": "Overview",
    "text": "Overview\nWhen seizures are not controlled by medication, one of the few remaining treatment options is brain surgery to remove the part of the brain that causes seizures. However, identifying those regions can be difficult, and people with epilepsy often continue having seizures after surgery. The main focus of my postdoc research is developing computational measures that help pinpoint pathological brain regions so that they can successfully be removed.\nThis study investigated the stability of one of our measures of brain “abnormalities” that we use to identify pathological brain regions. Our measure is computed from intracranial EEG, which is recorded from electrodes that are temporarily implanted directly on or in the brain. These recordings are usually multiple days and capture a variety of brain activity, including periods of sleep, wake, and seizures. To use our abnormality measure clinically, we first need to know whether the measure is robust. How much is it influenced by the type of brain activity? How much data is needed to reliably compute our measure?\nTo determine the impact of removing brain abnormalities, we additionally computed a summary metric, DRS, that captures differences in abnormality levels between the resected (i.e., hypothesised to be pathological) and spared (thought to be healthy) brain regions. We expected DRS to differ depending on whether the subject was seizure free after surgery – indicating that the hypothesised pathological regions indeed caused seizures – or not seizure free.\nWe found that although there is some variability in abnormalities at the level of different brain regions, the relationship between resected and spared brain regions (as captured by the metric DRS) remained relatively consistent over time in each subject. Additionally, we could use DRS to distinguish subjects that were seizure free versus not seizure free after surgery.\nWe used a variety of plots to visualise the data at the level of individual subjects as well as the entire cohort - I’ve included a couple examples here. This figure shows that brain abnormalities and the summary DRS metric were similar in time periods close to seizures (“peri-ictal”) and far away from seizures (“interictal”). Subjects were divided by whether they had good (ILAE 1, blue) or poor (ILAE 2-5, red) treatment outcomes.\n\n\n\n\n\n\n\nWang et al. 2023, Brain Communications\n\n\nThe figure below summarises results across subjects. We show the distribution of our summary measure in each subject and then used a machine learning classification metric to evaluate whether our measure distinguished subjects by their surgical outcomes.\n\n\n\n\n\n\n\nWang et al. 2023, Brain Communications"
  },
  {
    "objectID": "data_science/epilepsy-abnormalities/index.html#my-contributions",
    "href": "data_science/epilepsy-abnormalities/index.html#my-contributions",
    "title": "Epilepsy research: Do brain abnormalities change over time?",
    "section": "My contributions",
    "text": "My contributions\nThis project was a collaborative effort between five members of the lab as well as our clinical collaborators. Throughout the project, we met regularly to discuss preliminary results and brainstorm next steps. I was heavily involved in the analysis and writing. I worked with two other lab members to process and analyse the brain recording data, then drafted the manuscript’s methods, results, and supplementary material. I also generated most of the figures and final documented code, with feedback from the group."
  },
  {
    "objectID": "data_science/epilepsy-abnormalities/index.html#data-science-approaches",
    "href": "data_science/epilepsy-abnormalities/index.html#data-science-approaches",
    "title": "Epilepsy research: Do brain abnormalities change over time?",
    "section": "Data science approaches",
    "text": "Data science approaches\n\nData wrangling: Our lab has collaboratively created a large database of iEEG data along with patient, recording, and brain region metadata. A subset of this data was used and further organised for this project.\nSignal processing and time series frequency decomposition: We analysed brain activity in the frequency domain by computing power spectral densities and band power.\nNormative mapping: To determine if brain regions were abnormal, we compared brain activity in each patient to a normative map of our measure. This map describes normal brain dynamics in each brain region and was created using non-pathological brain regions from over 200 subjects from a separate iEEG study. Importantly, the normative map accounts for the well-known spatial variability in brain activity, allowing us to compare brain regions with different expected profiles of activity.\nMachine learning classification metrics: We defined our summary measure, DRS, as the area under the curve (AUC) for distinguishing resected and spared brain regions using abnormalities. We also used AUC to quantify whether DRS distinguishes patients who had good versus poor treatment outcomes.\nNon-parametric statistics: We used Wilcoxon rank sum tests to test whether our metric DRS significantly different between patients with good and patients with poor treatment outcomes.\nDimensionality reduction and time series decomposition: As part of the exploratory phase of this project, we also used approaches such as non-negative matrix factorisation and empirical mode decomposition to investigate possible spatiotemporal patterns in patient abnormalities."
  },
  {
    "objectID": "data_science/seizure-pathways/index.html",
    "href": "data_science/seizure-pathways/index.html",
    "title": "Epilepsy research: Variability in seizure pathways",
    "section": "",
    "text": "This work is published in Seizure pathways change on circadian and slower timescales in individual patients with focal epilepsy and Multiple mechanisms shape the relationship between pathway and duration of focal seizures."
  },
  {
    "objectID": "data_science/seizure-pathways/index.html#overview",
    "href": "data_science/seizure-pathways/index.html#overview",
    "title": "Epilepsy research: Variability in seizure pathways",
    "section": "Overview",
    "text": "Overview\nAlthough it is well-established that brain dynamics vary over time, we are just beginning to understand how that variability impacts neurological disorders. In people with epilepsy, fluctuations in brain dynamics impact not only when seizures occur but also features such as symptoms and seizure spread. My PhD research focused on visualising and quantifying this variability, with ultimate goal of inspiring treatments that adapt to changing brain dynamics.\nQuantitatively comparing seizures is challenging because seizures are such complex events. They have both spatial and temporal features: they change the activity of multiple brain regions, and that activity evolves from seizure start to finish. Seizures therefore need to be described using multivariate time series that capture spatiotemporal changes in brain dynamics. I described these time series as pathways through the space of possible brain dynamics.\nI visualised seizure pathways in two dimensions using a dimensionality reduction technique that tries to maintain high dimensional distances in a lower dimensional space; it essentially squishes the data into two dimensions so that it’s easier to visually compare different observations. This representation isn’t perfect, but it’s a good way to start investigating the structure and relationships in complex data.\nHere’s an example of this approach using one subject’s seizures. Each point represents the brain’s activity during a short part of a seizure. Points that are closer together represent similar patterns of brain activity. By connecting points in the same seizure, we see how brain activity changes during the seizure; this line is the seizure’s pathway.\n\n\n\n\n\nHere are more seizures from the same subject - you can see the seizure variability from both the brain recordings (A) and seizure pathways (C). I also quantified the “distance” or dissimilarity between each pair of pathways (D) to have an objective comparison of seizure pathways for downstream analysis.\n\n\n\n\n\n\n\nSchroeder et al. 2020, PNAS\n\n\nOne of my first observations was that different types of seizure pathways do not occur randomly - instead, more similar seizures tended to occur close together in time. For example, in (A) below, the purple seizure pathways migrated through network space as time passed, with similar pathways (e.g., seizures 6-8) occurring back-to-back. The rest of the figure quantifies the relationship between seizure pathways and their “temporal distance”: the amount of time between each pair of seizures.\n\n\n\n\n\n\n\nSchroeder et al. 2020, PNAS\n\n\nImportantly, quantifying seizure variability paves the way for additional studies by providing an objective measure of seizure (dis)similarity. For example, in my next study I asked if seizures with similar pathways also last a similar amount of time. I found that these different features weren’t necessarily linked (as shown by the examples below), which suggests that seizure pathways and durations can be altered by different mechanisms.\n\n\n\n\n\n\n\nSchroeder et al. 2022, Brain Communications"
  },
  {
    "objectID": "data_science/seizure-pathways/index.html#my-contributions",
    "href": "data_science/seizure-pathways/index.html#my-contributions",
    "title": "Epilepsy research: Variability in seizure pathways",
    "section": "My contributions",
    "text": "My contributions\nMy PhD research involved independent projects under the guidance of my supervisor. I undertook the analyses, communicated the results in papers and presentations, and drove the research directions. Throughout the projects, I incorporated feedback from the lab and our clinical collaborators."
  },
  {
    "objectID": "data_science/seizure-pathways/index.html#data-science-approaches",
    "href": "data_science/seizure-pathways/index.html#data-science-approaches",
    "title": "Epilepsy research: Variability in seizure pathways",
    "section": "Data science approaches",
    "text": "Data science approaches\n\nData wrangling: For this project, I extracted and organised seizure brain recordings, seizure metadata, and subject metadata.\nSignal processing: I used signal processing techniques such as filtering to preprocess brain signals.\nNetwork analysis: I described seizure dynamics as the time-varying functional connectivity between pairs of brain regions. Functional connectivity is a type of network that describes the similarity of pairs of time series (e.g., brain activity). I used coherence to quantify the similarity of pairs of brain signals in the frequency domain. I described each seizure’s time-varying network evolution as a pathway through the high dimensional network space.\nDimensionality reduction: I used non-negative matrix factorisation to reduce the dimensionality of the seizure networks and multidimensional scaling to visualise changes in seizure dynamics in a two dimensional space.\nTime series analysis: Seizure pathways are multivariate time series. To compare these time series, I used dynamic time warping and distance metrics. Dynamic time warping stretches pairs of time series to align similar dynamics, making it a useful approach for comparing time series that evolve at different rates. For example, two seizures may spread in a similar pattern, but at different rates. Dynamic time warping allows us to recognise their similar pathway, even though they progress through the pathway at different speeds.\nNon-parametric statistics: I used permutation tests to test for associations between seizure pathways and other seizure features.\nSimulations and modelling: I compared the observed changes in seizure pathways to a simple model of how seizures could change over different timescales.\nClustering: I used clustering approaches such as hierarchical clustering and k-means clustering to cluster seizures based on their features, as well as cluster evaluation metrics to determine the optimal number of clusters."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Gabrielle M. Schroeder\n\n\nData Science | Data Visualisation\n\n\n  \n    \n  \n  \nHi, I’m Gabrielle. I am a computational researcher and data visualisation enthusiast from Newcastle upon Tyne, UK. Read more about me or see examples of my data science, data vis, and generative art projects."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Gabrielle M. Schroeder",
    "section": "",
    "text": "I am computational researcher from Newcastle upon Tyne with a passion for uncovering and communicating insights from data.\nMy interest in data analysis was sparked by working with genetics data as an experimental biologist. In 2014, a Fulbright Postgraduate Award gave me the opportunity to transition to computational neuroscience and learn data science and modelling. These skills allow me to process, transform, and interrogate data to find clear patterns and stories. While most of my research analyses brain recordings and clinical data, I also work with a range of other data types for my personal and volunteer projects.\nI particularly enjoy data visualisation, especially when it involves (1) finding creative, effective ways to tell stories and/or (2) developing custom ways to explore and summarise complex data.\n\nEducation\nPhD in Computer Science | June 2022\nNewcastle University, Newcastle upon Tyne, UK\nMSc in Neuroinformatics | Dec. 2015\nNewcastle University, Newcastle Upon Tyne, UK\nBSc in Biological Sciences | May 2014\nRaleigh, North Carolina, US"
  },
  {
    "objectID": "data_vis.html",
    "href": "data_vis.html",
    "title": "Data visualisation",
    "section": "",
    "text": "I created these visualisations for personal projects, which I use to learn new tools, practice design concepts, and experiment with different visualisation techniques. Many of these projects are part of community initiatives such as Viz for Social Good (VFSG) and Tidy Tuesday.\nFor more examples of my data vis, see my data science projects, which heavily employ data visualisation for exploring data and communicating key findings. While many of those projects use standard types of charts, I also often use creative ways to visualise complex, high-dimensional data."
  },
  {
    "objectID": "data_vis.html#projects",
    "href": "data_vis.html#projects",
    "title": "Data visualisation",
    "section": "Projects",
    "text": "Projects"
  },
  {
    "objectID": "data_vis/vfsg-dwf/index.html",
    "href": "data_vis/vfsg-dwf/index.html",
    "title": "Viz for Social Good project: DWF ReconciliACTIONs",
    "section": "",
    "text": "This work was a volunteer project for Viz for Social Good (VFSG) in partnership with the Gord Downie & Chanie Wenjack Fund (DWF). The DWF aims to build cultural understanding and create a path towards reconciliation between Indigenous and non-Indigenous peoples in Canada. My visualisation was one of the top five designs selected by the DWF.\nCode for the data organisation, exploration, and visualisation is available on my GitHub."
  },
  {
    "objectID": "data_vis/vfsg-dwf/index.html#design-process",
    "href": "data_vis/vfsg-dwf/index.html#design-process",
    "title": "Viz for Social Good project: DWF ReconciliACTIONs",
    "section": "Design process",
    "text": "Design process\nThis project was an opportunity to stretch my design skills and practice layout, typography, and colour design concepts. It was also my first time working with branding guidelines outside of academic journal figure requirements.\n\nTools\nR, Adobe Illustrator, and Adobe InDesign.\n\n\nStorytelling\nThe DWF asked for visualisations that allowed them to explore and communicate their impact, as measured by reconciliACTIONs: meaningful actions that progress reconciliation between Indigenous and non-Indigenous peoples in Canada. I decided to make a report in a style similar to their yearly reports that would summarise their progress and be easy to share with stakeholders.\n\n\n\n\n\n\n\nThe report first lays out definitions for steps and stages (part of the DWF’s model for measuring the impact of reconciliACTIONs), while visualising progress within each of these categories. These first visualisations and descriptions give the reader a big picture overview of the DWF’s progress as well as a foundation for understanding the DWF’s model of reconciliACTIONs.\n\n\n\n\n\n\n\n\n\n\n\n\nThe next pages then explore reconciliACTIONs using the combined categorisation into both steps and stages, with each stage broken down into the five possible reconciliACTION steps. One visualisation shows how the number of reconciliACTIONs in each combined category changed over time, while the other shows the contributions of different types of reconciliACTIONs, coloured by their categories.\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, I end with a call-to-action to “Do Something” to progress reconciliation by providing a template for tracking reconciliACTIONs. The latter was inspired by the DWF’s comment that they do not have reconciliACTION data at the level of individuals – i.e., they do not know which actions any one person has taken. I therefore wanted to invite people to track their own progress. I decided to distinguish between steps, but not stages, on the tracking template since it may be more difficult for non-experts to categorise their reconciliACTIONs by stages. Additionally, most people’s reconciliACTIONs will be in only one or two of the stages, at least in the near future.\n\n\n\n\n\n\n\nThe final page of the report provides short descriptions the DWF and VFSG, as well as ways for people to find out more information about these two organisations.\n\n\n\n\n\n\n\n\n\nColours and symbols\nI worked with the DWF’s brand colours, but I also expanded the colour palette using three main hues from the striking colour palette of one of their main resources, The Secret Path film. I used the cooler hues to represent earlier stages of reconciliACTIONs, allowing the warming of the colour palette to symbolise the progression of reconciliation. Meanwhile, each step within each stage is encoded by the lightness of the hue. The colour therefore darkens as the steps become more difficult, which corresponds nicely to the increased impact of the latter steps. The combined hue and lightness encoding allowed me to visualise the combined categorisation of each reconciliACTION in the report’s latter visualisations.\nI also incorporated imagery and art that is central to the DWF’s messaging and identity, including Secret Path lyrics, train tracks, and watercolour artwork.\n\n\nData decisions\nI decided to use the simpler DWF model of “stages” of reconciliACTIONs, rather than the categorisation into “future states” of Canada, which would have doubled the number of categories. Based on my initial data explorations, I felt that the simpler stages representation captured most of the variability in the types of reconciliACTIONs thus far, and I therefore sacrificed some level of detail to make the visualisations more accessible. Further, since the report is geared towards DWF supporters and stakeholders, I thought the stages description was most appropriate since it focuses on the development of individual participants in their path to reconciliation. However, I did tie the stages back to the future states description to explain how stages fit in to the DWF’s more detailed model.\nSome of the reconciliACTIONs had negative numbers due to a decrease in the net number of newsletter subscribers. As suggested by the DWF, I decided to transform these negative numbers to zero to prevent them from detracting from other reconciliACTIONs in the same category. My reasoning was that unsubscribing did not undo or negate the participant’s previous action of subscribing. Additionally, the unsubscribing participants may decide to continue their reconciliation journey using other approaches, such as following the DWF on social media. If possible, the DWF could separately track the number of new subscriptions and unsubscriptions in future quarters to have different options for tracking these reconciliACTIONs.\nI also combined newsletter subscribers and mailable newsletter subscribers into one category for the “Many Ways to #DoSomething” visualisation of different reconciliACTION types.\n\n\nBrainstorming\nI’ve always gravitated towards sketching out visualisation ideas, but – inspired by reading about graphic and visualisation designers’ processes – I decided to more systematically incorporate sketches into developing these visualisations. Throughout the project, I used sketches to test out different ideas for vis types, layouts, and encodings. I sketched out initial ideas after first listening to the DWF’s Viz for Social Good presentation, but I also made sure to look at the data early on to understand its limitations and the feasibility of my approach. For example, I saw early on that the different scales in the data would make it tricky to compare reconciliACTIONs across different categories. I returned to sketching throughout the project to refine my early ideas, overcome roadblocks, and test out new ideas."
  },
  {
    "objectID": "data_vis/vfsg-dwf/index.html#acknowledgments",
    "href": "data_vis/vfsg-dwf/index.html#acknowledgments",
    "title": "Viz for Social Good project: DWF ReconciliACTIONs",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI used a slightly modified version of a generative art system designed by Danielle Navarro to make the irregular and smudged shapes in the #DoSomething tracking template. Her code is included in the art_functions.R script and is licensed under a Creative Commons Attribution 4.0 International License. The code is available from the Art from Code tutorial, session 3 and the associated GitHub page.\nDescriptions of the DWF and VFSG organisations are from their language guidelines and website, respectively."
  },
  {
    "objectID": "data_vis/macros-map/index.html#food-selection",
    "href": "data_vis/macros-map/index.html#food-selection",
    "title": "Macronutrients Map",
    "section": "Food selection",
    "text": "Food selection\nThe full USDA food database in the {NutrienTrackeR} package has an overwhelming number of foods: 7,754 . I pared this down to 1,530 foods using a combination of subsetting, heuristics, and a small amount of manual curation. I wanted to have a wide variety of foods while focusing on 1) less specific entries, 2) fresh and unprepared foods, and 3) foods with fewer ingredients (i.e., not complete meals or dishes). However, I kept some simpler processed and multi-ingredient foods, such as bread and yoghurt. I also removed some of the more unusual entries such as “raccoon.”\nMy wrangling steps included\n\nRemoving database categories that didn’t meet my criteria (e.g., “Fast Foods” and “Restaurant Foods”).\nRemoving entries with more than six words (excluding some phrases like “without salt” from the word count since they signified a simpler version of the food). This step removed very specific entries such as “Beef, chuck, shoulder clod, shoulder top and center steaks, separable lean and fat, trimmed to 0” fat, all grades, cooked, grilled” (21 words).\nRemoving alcoholic foods and beverages since they have a fourth macronutrient - alcohol - that I didn’t want to include in this visualisation. I identified these entries by estimating each food’s calories based on their carbs, fats, and protein content. I then found foods where this calculation greatly underestimated the true calorie content (since the remaining calories come from the alcohol). I removed any remaining alcohol-related entries using string matching to the food names.\nRemoving brand name foods. The USDA database capitalises most of the company names in the database, so these were easy to filter out by finding food names with multiple consecutive capital letters. I then manually filtered out some missed branded entries.\nRemoving entries that contained words that indicated cooking or processing - e.g., “cooked”, “roasted”, or “frozen”. I was careful here to keep longer versions of these strings that indicated the opposite - e.g., “uncooked”.\n\nTogether, these steps removed a lot of redundant entries, resulting in a more manageable map to explore.\nI also think this plot would work well using more tailored data, such as food from one person’s diet."
  },
  {
    "objectID": "data_vis/macros-map/index.html#layout",
    "href": "data_vis/macros-map/index.html#layout",
    "title": "Macronutrients Map",
    "section": "Layout",
    "text": "Layout\nThis visualisation uses a dimensionality technique called t-distributed Stochastic Neighbour Embedding (t-SNE), which embeds data in a small (e.g., two) number of dimensions to make it easier to visualise. The algorithm tries to optimise the new layout so that similar observations (here, foods) are placed close together. I based the similarity of the different foods off of their relative amounts of macronutrients and their calories per 100 g. Using relative macronutrient content (e.g., 20% protein) rather than the absolute macronutrient values (e.g., 10 g protein per 100 g) means that non-caloric content, such as water, is ignored for the embedding. I also normalised these features so that higher-magnitude features (such as calories) did not have a greater impact on food similarity.\nt-SNE is not deterministic - you can get different embeddings depending on where you first place each point. It also has a parameter, perplexity, that controls how much the algorithm focuses on nearby versus global similarities. To find an embedding that worked well for this visualisation, I systematically tried different starting configurations and perplexity values. I also experimented with scaling how much calories contributed to food similarity, as I wanted the layout to be primarily driven by the macronutrient content, with calories further separating foods with similar macronutrients. Ultimately, I divided the normalised calories by four to decrease their impact on the embedding.\nThe initial t-SNE embedding that I selected looked something like this:\n\n\n\n\n\nThis plot is pretty, but difficult to interact with because of the overlap between different foods, especially with the point size scaled by calories. I therefore used the R package {packcircles} to repel nearby points, resulting in a final layout without overlapping points. I also flipped the layout to work better with my text annotations - rotated or flipped embeddings are equivalent since they have the same distances between points. Here’s a non-interactive version of the final, annotated layout:\n\n\n\n\n\nWhile making this chart, I searched for any similar visualisations. I didn’t find any maps using these exact features, but there is a published static t-SNE embedding of USDA food data that uses the complete nutritional information (including micronutrient content such as vitamins). However, there are many more types of embedding approaches, so I may have missed other macronutrient representations - if you find any, I would love to see them!"
  },
  {
    "objectID": "data_vis/gardening-covid/index.html",
    "href": "data_vis/gardening-covid/index.html",
    "title": "Gardening’s growth during COVID",
    "section": "",
    "text": "These visualisations are a small personal project to practice using R and Datawrapper."
  },
  {
    "objectID": "data_vis/gardening-covid/index.html#gardenings-growth-during-the-covid-pandemic",
    "href": "data_vis/gardening-covid/index.html#gardenings-growth-during-the-covid-pandemic",
    "title": "Gardening’s growth during COVID",
    "section": "Gardening’s growth during the COVID pandemic",
    "text": "Gardening’s growth during the COVID pandemic\nWith the weather warming up in Newcastle upon Tyne, I’ve been spending more time in our new garden. As a novice gardener, I’ve also been doing more research online, Googling how and when to plant my various vegetable and flower seeds. These searches made me wonder how other gardeners use Google. Do their searches also vary over the course of the year?\nUsing Google Trends data, I began investigating garden searches in the UK, focusing on “how to garden” to capture interest in hobby gardening. I soon found that the expected seasonal changes weren’t the most interesting pattern in recent years:\n\n\n\n\n\n(Click on the chart for an interactive version.)\nCompared to the previous five years, 2020 saw more than double the number of “how to garden” searches after the first UK COVID-19 lockdown. In hindsight, the increased searches during 2020 are unsurprising, as the COVID-19 pandemic saw a dramatic increase in hobbiest gardeners. Like the pandemic, this higher interest persisted into 2021, with 2022 also seeing somewhat elevated searches. Interestingly, 2021 also bucks the usual seasonal pattern: “how to garden” searches increased a month earlier than expected, suggesting that gardeners were eager to get back outdoors after a winter of lockdowns!\nI can think of two main possibilities for the increased gardening interest:\n\nPeople looking for new at-home hobbies for themselves or their families. Many people had more free time due to furlough or working from home, and many usual hobbies and social activities were restricted by lockdowns.\nPeople who wanted access to fresh food without risking exposure to COVID-19 in shops or dealing with strange grocery delivery substitutions.\n\nTo better understand what drove the pandemic gardening Google searches, I investigated two more specific search terms: “how to grow vegetables” and “how to grow flowers.”\n\n\n\n\n\nBoth of these searches also dramatically increased during the first year of lockdowns. Although some flowers are edible or good companion plants, we can probably assume that flower searches were mostly hobby-motivated. Growing vegetables can also primarily be a hobby, but, interestingly, vegetable searches increased both sooner and more than flower searches in 2020. While home-grown crops take time to bear fruit (or veg), some searches may have been driven by initial lockdown fears or food order frustrations - especially if people suspected the pandemic would last beyond the first three week lockdown."
  },
  {
    "objectID": "data_vis/gardening-covid/index.html#bonus-stand-alone-r-visualisation",
    "href": "data_vis/gardening-covid/index.html#bonus-stand-alone-r-visualisation",
    "title": "Gardening’s growth during COVID",
    "section": "Bonus stand-alone R visualisation",
    "text": "Bonus stand-alone R visualisation\n\n\n\n\n\nHere I’ve added a third, more generic search: “how to grow food.” Food searches also increased during COVID, suggesting at least some gardening interest was driven by people who wanted to grow their own food."
  },
  {
    "objectID": "data_vis/tidy-tuesday/index.html",
    "href": "data_vis/tidy-tuesday/index.html",
    "title": "Tidy Tuesday (2023)",
    "section": "",
    "text": "These are my visualisations for Tidy Tuesday: a weekly R for Data Science data wrangling and visualisation challenge. Rough code for these visualisations is available on my GitHub.\n\nWeek 25: UFO Sightings\nI visualised when UFO sightings occur during the day and year. In the US, sightings tend to occur during the last few hours (during summer) or several hours (during winter) of the day, and sightings are especially common on Jan. 1 and July 4. The seasonal time-of-day variability in sightings may be because sightings tend to occur during dusk or the first part of the night.\n\n\n\n\n\n\n\n\n\n\nFewer UFO sightings were reported in the United Kingdom, but there are still some interesting trends:\n\n\n\n\n\n\n\nWeek 22: Verified Oldest People\nI visualised the years the oldest men and women lived and highlighted the people who set record ages."
  },
  {
    "objectID": "data_vis/vfsg-who/index.html",
    "href": "data_vis/vfsg-who/index.html",
    "title": "Viz for Social Good project: World Health Organisation",
    "section": "",
    "text": "I designed this visualisation for Viz for Social Good’s collaboration with the World Health Organisation (WHO). For this project, the WHO provided a dataset on global disabilities; their report on the data is available here. The WHO asked for impactful visualisations that raised awareness about disability. It was also key that the visualisation was accessible (e.g., by meeting accessibility standards). My visualisation was one of five (of 49) designs selected by the WHO for a panel presentation."
  },
  {
    "objectID": "data_vis/vfsg-who/index.html#anyone-can-have-a-disability",
    "href": "data_vis/vfsg-who/index.html#anyone-can-have-a-disability",
    "title": "Viz for Social Good project: World Health Organisation",
    "section": "Anyone can have a disability",
    "text": "Anyone can have a disability\nThe visualisation above represents every 1 million people in the world with one small dot. About 8,000 dots are grouped together in a circle to represent the global population of almost 8 billion people. Approximately 1 in 6 of these dots (around 1,300 dots total) are highlighted to represent the 1.3 billion people living with disabilities worldwide.\nPeople with disabilities are diverse:\n\nThey can be any sex: 44% are male and 56% are female\nThey can be any age: 7% are 0 to 14 years old, 63% are 15 to 59 years old, and 30% are at least 60 years old\nAnd they live in countries with different income levels: 7% in low income, 40% in lower-middle income, 33% in upper-middle income, and 20% in high income countries\n\nThese factors all impact the health inequities experienced by people with disabilities.\nVisualisation sources:\n\nVisualisation by Gabrielle M. Schroeder\nData source: World Health Organisation (2021 global disability data)\nViz for Social Good volunteer project"
  },
  {
    "objectID": "data_vis/vfsg-who/index.html#story",
    "href": "data_vis/vfsg-who/index.html#story",
    "title": "Viz for Social Good project: World Health Organisation",
    "section": "Story",
    "text": "Story\nI chose to present the key message that I took away from the WHO’s VFSG presentation: anyone can have a disability. In particular, disability is (1) common, and (2) impacts people with many different demographics. In other words, people with disabilities are a large and diverse group. I decided to keep the data analysis and statistics fairly simple to focus on this main message.\nAs such, I used the demographic information to answer the question, “What are the characteristics of people with disabilities?” (for example, what percentage of people with disabilities are female?) Importantly, my approach does not reveal the prevalence within each demographic, which could potentially lead to misinterpretations. For example, someone might assume that disability is less prevalent in high-income countries, even though high-income countries actually have the highest prevalence (see pages 23-24 of the WHO disability report). However, my visualisation can also correct erroneous assumptions. For example, although people who are 60+ years old are more likely to have a disability, the global population structure means that most people with disabilities are actually under 60 years old. Thus, these statistics can challenge stereotypes about people with disabilities.\nI also wanted to present this data in a memorable and impactful way. One of my first experiences seeing data visualisation used as a story-telling tool was the New York Time’s article on how race impacts economic mobility. Rather than just presenting bar charts or a Sankey diagram, the article uses animated points to represent the economic outcomes of individual people. Years later, I still remember that message because the data was connected to individuals. Inspired by that approach, I decided to try capturing the global scale and impact of disabilities by representing every one million people with one small point. Without animations, I don’t expect my visualisation to have the same impact as the New York Times charts, but my hope is that this visualisation will encourage people to sit with the data and mentally grasp the number of people living with disabilities. However, representing the data this way could also lead to accessibility issues if people struggle to perceive the small dots. I aimed to address these issues with other design choices (discussed below)."
  },
  {
    "objectID": "data_vis/vfsg-who/index.html#accessibility",
    "href": "data_vis/vfsg-who/index.html#accessibility",
    "title": "Viz for Social Good project: World Health Organisation",
    "section": "Accessibility",
    "text": "Accessibility\n\nData encoding\nAs I described above, I decided to represent one million people with a small dot. I then coloured these dots based on the people’s characteristics - e.g., whether they have disabilities. Since these small elements could be difficult for people with visual impairments to perceive, I ensured that all of the statistics were also encoded by the shapes formed by the dots:\n\nWhile the dots represented by people with disabilities are mixed into the circle that forms the global population, I extract those dots into a second, smaller circle that represents people with disabilities. The relative areas of those two circles encode the percentage of people with disabilities: the people with disabilities circle is approximately 1/6th the area of the global population circle.\nThe demographic information forms stacked bar charts, with the length of each section encoding the corresponding percentage. This double encoding should help everyone understand the data, as it’s much easier to perceive differences in lengths than differences in dot numbers.\n\n\n\nColour\nI avoided using the most problematic colour combinations for people with colour vision deficiencies, but I didn’t want to rely on that approach, especially since there are many different types of deficiencies. Therefore, to make my visualisation accessible, I also ensured that (1) neighbouring colours were differentiated by lightness as well as hue, and (2) no data encodings relied on colour alone. For example, each bar chart has vertical lines marking the boundaries between groups.\nTo check the impact of my colour choices on accessibility, I used Adobe’s colourblind checker and the Colbis (Color Blindness Simulator).\n\n\nFont, text, and contrast\nAfter researching factors that impact font accessibility, I decided to use Atkinson Hyperlegible, a font designed by the Braille Institute for people with low vision. It’s also freely available under the Open Font License, which was one of my requirements. Atkinson Hyperlegible uses extra space and exaggerated letterforms to make it easier to distinguish similar characters. The designed asymmetries also make it easier to distinguish letters that are mirror images of each other, such as p and q (e.g., compare the q in “inequities” vs. the p in “people” in my visualisation). The font was designed to be suitable for general audiences as well, and the distinct letterforms can improve readability for many people.\nAll of my text is either dark grey or purple that meets the WCAG 2.1 AAA standards for contrast against the white background (checked using Adobe’s accessibility tools). I also checked the contrast of the purple dots against the grey dots in the “global population” circle.\nThe size of all of the text is 10+ pt when the image width is 6.5+ inches, with the most important messages in larger font sizes. The visualisation has a high resolution so that it can be viewed at a larger size if desired.\n\n\nData accessibility\nThe image has the following alt text:\nA visualisation that represents every 1 million people in the world with one dot to show that 1 in 6 people, or 1.3 billion people worldwide, have a significant disability. To show the diversity of people with disabilities, the dots are rearranged into three stacked bar charts that provide sex, age, and country income level demographics.\nOne downside of using R to make a static visualisation is that, to my knowledge, there isn’t a way to allow screen readers to navigate the different chart elements. To make sure the key messages are still accessible, I also provide a text version of the main messages and statistics below the visualisation."
  },
  {
    "objectID": "data_vis/vfsg-who/index.html#other-design-choices",
    "href": "data_vis/vfsg-who/index.html#other-design-choices",
    "title": "Viz for Social Good project: World Health Organisation",
    "section": "Other design choices",
    "text": "Other design choices\n\nColour significance\nDuring this project, I learned that there are many colours used to represent different types of disability. I chose purple, which is becoming a symbol of disability as a whole.\n\n\nTool\nI made this visualisation using the R programming language, both for personal reasons (wanting to practice using the tidyverse/ggplot2 packages) and to have the large amount of control over the plot and text that R provides. The code is available on my GitHub."
  },
  {
    "objectID": "gen_art.html",
    "href": "gen_art.html",
    "title": "Generative art",
    "section": "",
    "text": "I started experimenting with generative art while learning R. These pieces were made by developing programs that generate and plot data according to certain rules. I enjoy discovering the variety of outputs a system can create within those constraints.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApertures\n\n\n\nR\n\n\nambient\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDrifts\n\n\n\nR\n\n\nambient\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data_science.html",
    "href": "data_science.html",
    "title": "Data science",
    "section": "",
    "text": "For the past several years, I’ve worked as a researcher in the Computational Neurology, Neuroscience, and Psychiatry (CNNP) Lab in the School of Computing at Newcastle University. I use a variety of computational, statistical, and mathematical approaches to find patterns in epileptic brain activity. I’ve summarised some of my main projects here, focusing on the high-level aims of each project – full details are available in the corresponding open access papers."
  },
  {
    "objectID": "data_science.html#projects",
    "href": "data_science.html#projects",
    "title": "Data science",
    "section": "Projects",
    "text": "Projects"
  }
]